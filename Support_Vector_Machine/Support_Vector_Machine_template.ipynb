{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Support_Vector_Machine_template.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipdpMv0wbhEX",
        "colab_type": "text"
      },
      "source": [
        "# Implemeting SVM from scratch using Python\n",
        "![](https://github.com/decodrtechnologies/Data-Science/blob/master/Support_Vector_Machine/svm.PNG)\n",
        "\n",
        "1. About SVM (General required for algo)\n",
        "\t* For all xi in training Data:\n",
        "\t\t * ```\t\n",
        "\t\t \txi.w + b <= -1   if yi = -1 (belongs to -ve class)\n",
        "\t\t \txi.w + b >= +1\tif yi = +1 (belongs to +ve class)\n",
        "\t\t \t\t\t\tor\n",
        "\t\t \t \t__yi(xi.w+b) >= 1__\n",
        "\t\t \t```\n",
        "\t* for all support vectors(SV) (data points which decides margin)\n",
        "\t\t* ```\n",
        "\t\t\txi.w+b = -1    here xi is -ve SV and yi is -1\n",
        "\t\t\txi.w+b = +1    here xi is +ve SV and yi is +1\n",
        "\t\t\t```\n",
        "\t* For decision Boundary `yi(xi.w+b)=0` here xi belongs to point in decision boundary\n",
        "\t* Our Objective is to maximize Width W\n",
        "\t\t* `W = ((X+ - X-).w)/|w|`\n",
        "\t\t* or we can say minimize |w|\n",
        "\t* Once we have found optimized w and b using algorithm\n",
        "\t\t* `x.w+b = 1` is line passing through +ve support vectors\n",
        "\t\t* `x.w+b = -1` is line passing through -ve support vectors\n",
        "\t\t* `x.w+b = 0` is decision boundary\n",
        "\t* It is not necessary that support vector lines always pass through support vectors\n",
        "\t* It is a Convex Optimization problem and will always lead to a global minimum\n",
        "\t* This is Linear SVM means kernel is linear\n",
        "\n",
        "2. Algorithm in Code (See code for better understanding)\n",
        "\t1. Start with random big value of w say(w0,w0) we will decrease it later\n",
        "\t2. Select step size as `w0*0.1` \n",
        "\t3. A small value of b, we will increase it later\n",
        "\t\t* b will range from (-b0 < b < +b0, step = `step*b_multiple`)\n",
        "\t\t* This is also computational expensive. So select b0 wisely \n",
        "\t4. We will check for points xi in dataset:\n",
        "\t\t* Check will for all transformation of w like (w0,w0), (-w0,w0), (w0,-w0), (-w0,-w0)\n",
        "\t\t* if not `yi(xi.w+b)>=1` for all points then break\n",
        "\t\t* Else find |w| and put it in dictionary as key and (w,b) as values \n",
        "\t5. \n",
        "\t\t* If w<=0 then current step have been completed and go to step 6\n",
        "\t\t* Else decrease w as (w0-step,w0-step) and continue with step 3\n",
        "\t6.  Do this step until step becomes `w0*0.001` because futher it will be point of expense\n",
        "\t\t* `step = step*0.1` \n",
        "\t\t* go to step 3\n",
        "\t7. Select (w,b) which has min |w| form the dictionary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L1PIrtsXQ5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing some basic libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "style.use('ggplot')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt-q62nIb4jY",
        "colab_type": "text"
      },
      "source": [
        "### Creating SVM algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kttJ3j9yXYpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define class svm \n",
        "class SVM(object):\n",
        "    \n",
        "    # define a method fit which accepts linear data\n",
        "    def fit(self,data):\n",
        "\n",
        "       \n",
        "        # conver the data into an array\n",
        "       \n",
        "       \n",
        "        # use two variable to store max features and min features             \n",
        "       \n",
        "\n",
        "        # create a variabel step_size \n",
        "\n",
        "\n",
        "        #with smaller steps our margins and db will be more precise\n",
        "        # write your code here        \n",
        "          \n",
        "        \n",
        "      \n",
        "        \"\"\"\n",
        "        objective is to satisfy yi(x.w)+b>=1 for all training dataset such that ||w|| is minimum\n",
        "        for this we will start with random w, and try to satisfy it with making b bigger and bigger\n",
        "        \"\"\"\n",
        "        #make step smaller and smaller to get precise value\n",
        "        # write your code here\n",
        "\n",
        "          \n",
        "\n",
        "                \n",
        "                #after w[0] or w[1]<0 then values of w starts repeating itself because of transformation\n",
        "               \n",
        "                    \n",
        "            # sort ||w|| to put the smallest ||w|| at poition 0 \n",
        "            \n",
        "            #find optimal values of w,b\n",
        "            \n",
        "            \n",
        "            #start with new latest_optimum (initial values for w)\n",
        "           \n",
        "    \n",
        "    \n",
        "\n",
        "    # define a function predict which will accept the features\n",
        "    def predict(self,features):\n",
        "       # write your code here and return the value\n",
        "        return ()\n",
        "    \n",
        "    \n",
        "    # create a function visualize for data visualization\n",
        "    def visualize(self):\n",
        "        # write your code here\n",
        "\n",
        "\n",
        "        # hyperplane = x.w+b (actually its a line)\n",
 
        "\n",
        "        def hyperplane():\n",
        "           \n",
        "            #returns a x2 value on line when given x1\n",
        "            # write your code and return the value\n",
        "            return ()   \n",
        "\n",
        "        \n",
        "        # (w.x+b)=1\n",
        "        # positive support vector hyperplane\n",
        "        # write your code here\n",
        "\n",
        "\n",
        "        # (w.x+b)=-1\n",
        "        # negative support vector hyperplane\n",
        "        # write your code here\n",
        "\n",
        "\n",
        "        # (w.x+b)=0\n",
        "        # db support vector hyperplane\n",
        "        # write your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_WMPgnBcCtX",
        "colab_type": "text"
      },
      "source": [
        "### Testing the Algorithm with a basic dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcpdP4OvXcj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining a basic data\n",
        "data_dict = {-1:np.array([[1,7],[2,8],[3,8]]),1:np.array([[5,1],[6,-1],[7,3]])}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k97t4NlKXlr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a model \n",
        "\n",
        "\n",
        "#fit the data\n",
        "\n",
        "\n",
        "#lets call visualize function to view the data\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
