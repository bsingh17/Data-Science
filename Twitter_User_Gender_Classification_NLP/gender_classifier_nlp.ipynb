{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7346e67499d9a00dd998f07f827fefbbaa0a790f"
   },
   "source": [
    "# INTRODUCTION<br><br>\n",
    "**In this kernel, we will use NLTK and Natural Language Processing(NLP) to predict the gender.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Import libraries numpy, pandas, matplotlib, seaborn\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results written to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "### Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "55c9c1c04fdff1b3caa43360cf6c4107d9d0beb4"
   },
   "outputs": [],
   "source": [
    "# import twitter data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5568b807326ba6e77a145df77f2b5d3db3220c71"
   },
   "outputs": [],
   "source": [
    "#Concatenate the data attributes gender and description\n",
    "\n",
    "\n",
    "#Drop the NaN values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e16dfc57c63f82d2cc144214eecdf1513981e20"
   },
   "outputs": [],
   "source": [
    "# Inspect  the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3deff8f51f6d47d8b3d94af084d0380548460916"
   },
   "outputs": [],
   "source": [
    "#Retrieve the shape of the dataframe \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eee1cd412e68655cf49aea32884812249a9753bf"
   },
   "outputs": [],
   "source": [
    "#Define the data gender variable (1 for female and 0 for male)\n",
    "\n",
    "\n",
    "#Inspect the data again(take 10 values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9976f3ec86ac2c0044fec29ba60040c09edd7891"
   },
   "outputs": [],
   "source": [
    "# Retrieve any one description \n",
    "# We will first employ the cleaning of the text for one description and\n",
    "# then clean all the descriptions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4a6706de5d839df851df94d365a91b07af9ad035"
   },
   "source": [
    "### Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc1ce1b0524b4dc502a78373915e31add3aca563"
   },
   "outputs": [],
   "source": [
    "# Regular expression to be used RE =>> \"[^a-zA-Z]\"\n",
    "#Import the regex library\n",
    "\n",
    "\n",
    "# Use re.sub to filter out the text from the raw data\n",
    "# Also make sure all the text is lower case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "728a1a984c18d51f3fb3a82c35c879c1331391a5"
   },
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df2ff835d44c1b28f2f526a7be90cbe189a0c8f3"
   },
   "outputs": [],
   "source": [
    "#Use nltk libraries to remove irrelevant words known as stopwords\n",
    "\n",
    "# Import the libraries \n",
    "\n",
    "\n",
    "\n",
    "#remove irrelavent words for e.g. and,the ...\n",
    "#Tokenize the text using word_tokenize \n",
    "#You can also use .split function and then tokenize the words\n",
    "#if we use word_tokenize instead of split it will be better\n",
    "#split() = shouldn't => shouldn't\n",
    "#word_tokenize() = shouldn't => shouldn't and n't separate as two word\n",
    "#Tolenize the text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Filter the stopwords from the text and print the filtered text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "baf7ac67dd99d4862d05b6cb2843cb8581851529"
   },
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5327f3b78cf09fee2fa7be234853c119bcd6f47"
   },
   "outputs": [],
   "source": [
    "#Lemmatization = loved => love\n",
    "#import the nltk library\n",
    "\n",
    "\n",
    "#Employ lemmatization to the text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "65a2a1f65e76a45ee08d25679ddcb4a27966d537"
   },
   "outputs": [],
   "source": [
    "# Rejoin the tokenized words into a corpus and print the cleaned text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dfc912fb19c632215d35352e53502ca2287a9149"
   },
   "source": [
    "### Apply to All Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a28c91ac696d580d821bc4aee40d860ba43f69e4"
   },
   "outputs": [],
   "source": [
    "#Apply everything you did above to all the remaining descriptions\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a69d229dc6ae19d4bc78a6a87e0afea1a029483d"
   },
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a311d5f174ab11f38cf82623913f811f2c8a6d57"
   },
   "outputs": [],
   "source": [
    "#Import the sklearn feature extraction from text library to vectorize the count\n",
    "\n",
    "\n",
    "\n",
    "# Define max_features as the maximum number of features you want to employ.\n",
    "# Use the count vectorizer after defining a specific number as max_fatures\n",
    "\n",
    "\n",
    "\n",
    "#count_vectorizer = CountVectorizer(stop_words = \"english\")\n",
    "#Define the sparce matrix\n",
    "\n",
    "\n",
    "\n",
    "# Print the most common words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d9484f080c638da7eff571b380195df8b2eef4f"
   },
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "736a349b318334b1d4f57045d883a3e4234a0b9e"
   },
   "outputs": [],
   "source": [
    "#Define the x and y variables(y=0 for female and y=0 for male)\n",
    "\n",
    "\n",
    "# train test split (80-20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "782d1f2b0e2cc5666b53646e67a5caf82e0b2496"
   },
   "source": [
    "### Apply Naive Bayes Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ff47650b02e92473b676c2ca812f6561a629cbbb"
   },
   "outputs": [],
   "source": [
    "#Apply Naive Bayes\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ee183271e64d6d1bb6c5e57ac85081ca777c8a3"
   },
   "outputs": [],
   "source": [
    "# Plot the Confusion Matrix for Naive Bayes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e93373995e666949e6ed874f9ade07323ca1bad9"
   },
   "source": [
    "### Apply Random Forest Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8acc313de9b26f7b2e421dc25285069010121fa8"
   },
   "outputs": [],
   "source": [
    "# Apply Random Forest Machine Learning Algorithm\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa005475ccbb24e2884a6ba8f9521d73d904be62"
   },
   "outputs": [],
   "source": [
    "# Plot the Confusion Matrix for Random Forest\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
