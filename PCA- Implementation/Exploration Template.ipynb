{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dermatology Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * This database contains 34 attributes, 33 of which are linear\n",
    "   valued and one of them is nominal. \n",
    "\n",
    "\n",
    " * The differential diagnosis of erythemato-squamous diseases is a real\n",
    "   problem in dermatology. They all share the clinical features of\n",
    "   erythema and scaling, with very little differences. The diseases in\n",
    "   this group are psoriasis, seboreic dermatitis, lichen planus, \n",
    "   pityriasis rosea, cronic dermatitis, and pityriasis rubra pilaris.\n",
    "   Usually a biopsy is necessary for the diagnosis but unfortunately\n",
    "   these diseases share many histopathological features as\n",
    "   well. Another difficulty for the differential diagnosis is that a\n",
    "   disease may show the features of another disease at the beginning\n",
    "   stage and may have the characteristic features at the following stages. \n",
    "   Patients were first evaluated clinically with 12 features.\n",
    "   Afterwards, skin samples were taken for the evaluation of 22\n",
    "   histopathological features. The values of the histopathological features\n",
    "   are determined by an analysis of the samples under a microscope. \n",
    "\n",
    "\n",
    " * In the dataset constructed for this domain, the family history feature\n",
    "   has the value 1 if any of these diseases has been observed in the\n",
    "   family, and 0 otherwise. The age feature simply represents the age of\n",
    "   the patient. Every other feature (clinical and histopathological) was\n",
    "   given a degree in the range of 0 to 3. Here, 0 indicates that the\n",
    "   feature was not present, 3 indicates the largest amount possible,\n",
    "   and 1, 2 indicate the relative intermediate values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * The Dataset is taken from here - [Dermatology Dataset](https://archive.ics.uci.edu/ml/datasets/dermatology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps Involved:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. Importing the library\n",
    " 2. Loading the Dataset\n",
    " 3. Structure of the Dataset\n",
    " 4. Exploration of Dataset\n",
    "  * Statistics\n",
    "  * Data Cleaning\n",
    "  * Heat Map\n",
    " 5. PCA Implementation\n",
    " 6. Machine learning Model\n",
    "  * Splitting the Dataset\n",
    "  * Training the Model\n",
    "  * Prediction\n",
    "  * Model Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the required Packages like numpy ,pandas etc.\n",
    "#Import the library for the plots also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load the dataset of Dermatology Dataset''';\n",
    "#Use the Pandas or numpy to read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''If the data is taken from the numpy,try to convert it into dataframe ''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The Last Column, i.e ClassCode of the plant is your target value''';\n",
    "#Print the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the columns names in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the target value in some other variable for further analysis\n",
    "'''Use columns name for this indexing''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Structure of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the describe of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing or Null Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null value in the features using isnull function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for nan value in the features using isnan function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Check whether you get any null value or nan value''';\n",
    "#If found try to avoid that, and if not proceed to next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploration of the Dataset\n",
    "\n",
    "## Statistics\n",
    "\n",
    "For our very first coding implementation, we will calculate descriptive statistics about the Dermatology Dataset. Since numpy has already been imported for us, using this library to perform the necessary calculations. These statistics will be extremely important later on to analyze various prediction results from the constructed model.\n",
    "\n",
    "In the code cell below, we will need to implement the following:\n",
    "\n",
    " * Calculate the minimum, maximum, mean, median, and Unique of 'ClassCode'. Store each calculation in their respective variable.\n",
    " * Store each calculation in their respective variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mininum of the 'ClassCode'\n",
    "\n",
    "\n",
    "#Maximum of the 'ClassCode'\n",
    "\n",
    "\n",
    "#Mean of the 'ClassCode'\n",
    "\n",
    "\n",
    "#Median of the 'ClassCode'\n",
    "\n",
    "\n",
    "#Unique of the 'ClassCode'\n",
    "\n",
    "# Show the calculated statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After statistics analysis, go for the graphical representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You'll use displot from seaborn on the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get some observation from the above graph and perform the filteration at this level, if you found.''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for value_counts for target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for any feature that need to resolve\n",
    "#Hint: Check for \"?\" in feature, search for it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the value with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace nan with other statistics, like mean, mode etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Check for Correlation in the Dataset''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use heat map in the seaborn library to get the correlation graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A heat map uses a warm-to-cool color spectrum to show dataset analytics, namely which parts of data receive the most attention.\n",
    "\n",
    "The correlation coefficient ranges from -1 to 1. If the value is close to 1, it means that there is a strong positive correlation between the two variables. When it is close to -1, the variables have a strong negative correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is there any relations among the features?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Try to get some correlation from the above graph, and try to use the features \n",
    "   only with the more positive correlation and more correlation''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. PCA Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Class code column is the value that needs to be predicted from the analysis. \n",
    "#Hence you will have to split X and y(Features and labels) based on this information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call Standard Scaler fit transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Algebra for PCA\n",
    "\n",
    " * Calculating the covarience matrix\n",
    " * Calculating the eigen values and eigen vectors\n",
    " * Forming Principal Components\n",
    " * Projection into the new features space\n",
    "\n",
    "### a). Calculating the covarience matrix\n",
    "\n",
    " * Covarience matrix is a matrix of variances and covariances(or correlations) among every pair of the m variable.\n",
    " * It is square, symmetric matrix.\n",
    " * Covarience matrix (S) = X.T* X, we can find it by using numpy matmul() function in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the covarience matrix which is : X.T*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matrix multiplication using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the shape of variance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b). Calculating the eigen values and eigen vectors\n",
    "\n",
    " * ƛ is an eigenvalue for a matrix X if it is a solution of the characteristic equation: det( ƛ*I - A ) = 0 Where, I is the identity matrix of the same dimension as X\n",
    " * The sum of all m eigenvalues equals the trace of S (the sum of the variances of the original variables).\n",
    " * For each eigenvalue ƛ, a corresponding eigen-vector v, can be found by solving : ( ƛ*I - A )v = 0\n",
    " * The eigenvalues, ƛ1, ƛ2, ... ƛm are the variances of the coordinates on each principal component axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find top two eigen value and corresponding eigen vectors\n",
    "#for projecting onto a 2-Dimension space.\n",
    "\n",
    "\n",
    "#The parameter 'eigvals' is defined(low value to high value)\n",
    "#eigh function will return the eigen value in ascending order\n",
    "#this code generates only top two eigen values \n",
    "\n",
    "#convert the eigen vectors into (2,d) shape for easyness of further computations\n",
    "\n",
    "#the vectors[1] represent the eigen vector corresponding 1st principal eigen vector\n",
    "#the vectors[0] represent the eigen vector corresponding 2nd principal eigen vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c). Forming Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project the original data sample on the plane \n",
    "#formed by two principal eigen vectors by vector-vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the new data point shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d). Projection into the new features space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Dataframe having 1st principal & 2nd principal\n",
    "\n",
    "#create new_dataframe for plotting labeled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 2d data points with seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Machine learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Try to get any Classification Model''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use train_test_split\n",
    "'''split the data in 70:30 ratio''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the shape of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the shape of test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use inbuilt classifier model from scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model on training Data using inbuilt .fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the y_predict from .predict function on X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the Model Score\n",
    "#Print the Graph related"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
